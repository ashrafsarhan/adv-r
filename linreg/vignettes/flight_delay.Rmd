---
title: "Vignette for ridgereg"
author: "Yumeng Li, Mattias Karlsson, Ashraf Sarhan"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Vignette Goal
This vignette guides you through how to predict observations using the ridgereg() function from package Linreg. In this case we will predict flight delays based on two predictors (distance, wind_speed).

## Function Discription
Ridgereg(formula, data, lambda) 

Ridge regression can be a good alternative when we have a lot of covariates (when p > n) or in the situation of multicollinearity.

## Data
Read in the weather dataset and the flights dataset from the nycflights13 package and remove eventual variables you do not believe to have a predictive value.
```
library("nycflights13")
flights_data <- flights
weather_data <- weather
all_data <- plyr::join(flights_data, weather_data, by=c('origin', 'year', 'time_hour'), type='inner')
trgt_data <- all_data[,c('flight', 'origin', 'dest', 'arr_delay', 'distance', 'wind_speed')]

#Get rid of NA rows (Missing values) 
trgt_data <- na.omit(trgt_data)

#Get rid of negative rows 
negrows <- which(trgt_data$arr_delay < 0)
trgt_data <- trgt_data[-negrows,]
```
Variable dep\_delay say how many minutes the plane was delayed. origin, year, time\_hour variables are used to match the weather data. Splits the data so dep_delays contains only positive values, because we are only interested in flight that has been delayed.
```{r, echo = FALSE}
library("nycflights13")
flights_data <- flights
weather_data <- weather
all_data <- plyr::join(flights_data, weather_data, by=c('origin', 'year', 'time_hour'), type='inner')
trgt_data <- all_data[,c('flight', 'origin', 'dest', 'arr_delay', 'distance', 'wind_speed')]

#Get rid of NA rows (Missing values) 
trgt_data <- na.omit(trgt_data)

#Get rid of negative rows 
negrows <- which(trgt_data$arr_delay < 0)
trgt_data <- trgt_data[-negrows,]
head(trgt_data)
```

Weather data set contains the explanatory variables to be used in the model.
```
precip = Preciptation, in inches
wind_speed = Wind speed (in mph)
visib = Visibility in miles
month = Time of recording
```
## Test/Train/Validation dataset
We will now divide the data set into three parts, testing, training and validation sets. The division of the observations to each set is, 5%, 80% and 15%
Each set is
```
#Partition data set in training 80%, validation 15%, testing 5%.
inTraining <- createDataPartition(trgt_data$arr_delay, p=.80, list=FALSE)
training <- trgt_data[ inTraining,]
cat('training: ', nrow(training))
notTraining <- trgt_data[-inTraining,]
inValidation <- createDataPartition(notTraining$arr_delay, p=.15, list=FALSE)
validation <- notTraining[inValidation,]
cat('validation: ', nrow(validation))
testing <- notTraining[-inValidation,]
cat('testing: ', nrow(testing))

```
### Centering and Scaling data set
```
#Centering and Scaling
preProcValues <- preProcess(trgt_data[,4:6], method = c("center", "scale"))
training <- predict(preProcValues, training)
validation <- predict(preProcValues, validation)
testing <- predict(preProcValues, testing)
```

## Ridge Regression - Validation dataset
Train ridge regressions models for diâ†µerent values of lambda and evaluate the root mean squared error (RMSE)on the validation set.
In this case, we check the lambda values between 0-5.
```
#Set lamada grid
lambdaGrid <- seq(1,5,length=10)
#Set search grid for lamada parameters
tuneGrid= expand.grid(lambda=lambdaGrid) 
# define training control
trControl <- trainControl(method="repeatedCV", number=5)
# Fit a ridge regression model using the validation dataset
set.seed(100)
model1 <- train(arr_delay ~ distance+wind_speed, data = validation, method = "ridge", 
               tuneGrid=tuneGrid, trControl=trControl)
# summarize results
print(model1)
```
### Output:
```
Ridge Regression 

4136 samples
   2 predictors

No pre-processing
Resampling: Cross-Validated (5 fold, repeated 5 times) 
Summary of sample sizes: 3309, 3308, 3310, 3309, 3308, 3309, ... 
Resampling results across tuning parameters:

  lambda    RMSE       Rsquared   
  1.000000  0.9895768  0.003147062
  1.444444  0.9895767  0.003147900
  1.888889  0.9895767  0.003148479
  2.333333  0.9895767  0.003148903
  2.777778  0.9895767  0.003149228
  3.222222  0.9895766  0.003149484
  3.666667  0.9895766  0.003149691
  4.111111  0.9895766  0.003149862
  4.555556  0.9895766  0.003150006
  5.000000  0.9895766  0.003150128

RMSE was used to select the optimal model using  the smallest value.
The final value used for the model was lambda = 5. 
```

## Ridge Regression - Test dataset
We now predict the observations for the test set by using the evaluated lambda value above.
```
# Predict the test set using the optimal lamada
set.seed(100)
model2 <- train(arr_delay ~ distance+wind_speed, data = training, method = "ridge", 
                tuneGrid=expand.grid(lambda=5))
pred <- predict(model2, newdata = testing)
# summarize results
print(model2)
```
The RMSE value for the model is presented below.
```
Ridge Regression 

110234 samples
     2 predictors

No pre-processing
Resampling: Bootstrapped (25 reps) 
Summary of sample sizes: 110234, 110234, 110234, 110234, 110234, 110234, ... 
Resampling results:

  RMSE       Rsquared   
  0.9997285  0.001950152

Tuning parameter 'lambda' was held constant at a value of 5
```
#### Include ridgereb in caret package
```
svmGrid <- function(x, y, len = NULL, search = "grid") {
  #library(kernlab)
  ## This produces low, middle and high values for sigma 
  ## (i.e. a vector with 3 elements). 
  #sigmas <- sigest(as.matrix(x), na.action = na.omit, scaled = TRUE)  
  ## To use grid search:
  if(search == "grid") {
    out <- expand.grid(lambda = c(0, 10^seq(-1, -4, length = len - 1)))
  } else {
    ## For random search, define ranges for the parameters then
    ## generate random values for them
    out <- data.frame(lambda = 10^runif(len, min = -5, 1))
  }
  out
}

train_x <- validation_sample
train_y <- validation_sample$dep_delay
train_p <- "lambda"
train_y <- 5

svmFit <- function(x,y,param){
  ksvm(as.matrix(x),
       y = y,
       kernel = rbfdot,
       kpar = list(lambda = param$lambda))
}

ridge_list <- list(library = "linreg",
                   type = "regression",
                   parameters = data.frame(parameter = "lambda",
                                           class = "numeric",
                                           label = "Lambda"),
                   grid = svmGrid,
                   #(x = train_x,y = train_y, param = train_p)
                   fit = svmFit)

Lambda_optimize <- train(data = validation_sample,
      x = validation_sample[1:100,3:5],
      y = c(1:100),
      form = call_f,
      type = ridge_list,
      maxit = 100)
```


